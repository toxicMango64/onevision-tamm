{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-23T05:42:10.362586Z",
     "iopub.status.busy": "2025-04-23T05:42:10.362259Z",
     "iopub.status.idle": "2025-04-23T05:42:26.717782Z",
     "shell.execute_reply": "2025-04-23T05:42:26.717111Z",
     "shell.execute_reply.started": "2025-04-23T05:42:10.362563Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models import efficientnet_b7, EfficientNet_B7_Weights, resnet50, EfficientNet_B7_Weights\n",
    "from PIL import Image\n",
    "\n",
    "sns.set(style=\"whitegrid\", palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T05:42:26.719548Z",
     "iopub.status.busy": "2025-04-23T05:42:26.719075Z",
     "iopub.status.idle": "2025-04-23T05:42:26.723596Z",
     "shell.execute_reply": "2025-04-23T05:42:26.722742Z",
     "shell.execute_reply.started": "2025-04-23T05:42:26.719515Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Try SMOTE? (Not ideal, it sucks)\n",
    "# Try Cost-Sensitive Learning \n",
    "# Get from Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T05:42:26.725042Z",
     "iopub.status.busy": "2025-04-23T05:42:26.724635Z",
     "iopub.status.idle": "2025-04-23T05:42:26.777084Z",
     "shell.execute_reply": "2025-04-23T05:42:26.776374Z",
     "shell.execute_reply.started": "2025-04-23T05:42:26.725010Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# PATH = \"/kaggle/input/tammathon-task-2\"  # path to data in the kaggle\n",
    "PATH = \"/root/tammathon/data\" # path to data in the server\n",
    "\n",
    "train_df = pd.read_csv(f\"{PATH}/train.csv\")\n",
    "valid_df = pd.read_csv(f\"{PATH}/val.csv\")\n",
    "test_df = pd.read_csv(f\"{PATH}/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T05:42:26.779390Z",
     "iopub.status.busy": "2025-04-23T05:42:26.778561Z",
     "iopub.status.idle": "2025-04-23T05:42:26.791487Z",
     "shell.execute_reply": "2025-04-23T05:42:26.790596Z",
     "shell.execute_reply.started": "2025-04-23T05:42:26.779364Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df.iloc[0]['path'].split('/')[0]\n",
    "train_df.iloc[0]['filename'].split('/')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T05:49:54.409311Z",
     "iopub.status.busy": "2025-04-23T05:49:54.409006Z",
     "iopub.status.idle": "2025-04-23T05:49:54.421164Z",
     "shell.execute_reply": "2025-04-23T05:49:54.420149Z",
     "shell.execute_reply.started": "2025-04-23T05:49:54.409289Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ICAODataset(Dataset):\n",
    "    def __init__(self, root_dir, dataframe, transforms=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.transforms = transforms\n",
    "        self.subset = dataframe.iloc[0]['path'].split('/')[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        img_path = os.path.join(self.root_dir, self.subset, row['path'])\n",
    "        img = Image.open(img_path).convert(\"RGB\")  # ensure 3 channels\n",
    "        \n",
    "        label = torch.tensor(row['label'], dtype=torch.float32)  # binary case\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "        return img, torch.tensor([label])\n",
    "\n",
    "\n",
    "train_transforms = v2.Compose([\n",
    "    v2.Resize(600),\n",
    "    v2.RandomHorizontalFlip(p=0.3),\n",
    "    v2.ColorJitter(0.4, 0.4, 0.4, 0.4),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                 std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "valid_transforms = v2.Compose([\n",
    "    v2.Resize(600),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                 std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_data = ICAODataset(PATH, train_df.rename(columns={\"filename\": \"path\"}), transforms=train_transforms)\n",
    "valid_data = ICAODataset(PATH, valid_df.rename(columns={\"filename\": \"path\"}), transforms=valid_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_data, num_workers=0, shuffle=True, \n",
    "                          pin_memory=True)\n",
    "valid_loader = DataLoader(valid_data, num_workers=0, shuffle=False, \n",
    "                          pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T05:49:56.506094Z",
     "iopub.status.busy": "2025-04-23T05:49:56.505304Z",
     "iopub.status.idle": "2025-04-23T05:49:56.517020Z",
     "shell.execute_reply": "2025-04-23T05:49:56.515920Z",
     "shell.execute_reply.started": "2025-04-23T05:49:56.506061Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EffNetB7Base(nn.Module):\n",
    "    def __init__(self, n_classes=1):\n",
    "        super().__init__()\n",
    "        model = efficientnet_b7(weights=EfficientNet_B7_Weights.IMAGENET1K_V1)\n",
    "        in_features = model.classifier[1].in_features\n",
    "        \n",
    "        self.backbone = nn.Sequential(*list(model.children())[:-1])\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Linear(in_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.backbone(x)\n",
    "        out = self.pool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.classifier(out)\n",
    "        return out  # raw logits\n",
    "\n",
    "\n",
    "class ResNet50Base(nn.Module):\n",
    "    def __init__(self, n_classes=1):\n",
    "        super().__init__()\n",
    "        model = resnet50(weights = ResNet50_Weights.IMAGENET1K_V1)\n",
    "        in_features = model.fc.in_features\n",
    "\n",
    "        # Remove the original classifier\n",
    "        self.backbone = nn.Sequential(*list(model.children())[:-1])\n",
    "        self.classifier = nn.Linear(in_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.backbone(x)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T05:50:03.896122Z",
     "iopub.status.busy": "2025-04-23T05:50:03.895293Z",
     "iopub.status.idle": "2025-04-23T05:50:03.902066Z",
     "shell.execute_reply": "2025-04-23T05:50:03.900948Z",
     "shell.execute_reply.started": "2025-04-23T05:50:03.896095Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        probs = torch.sigmoid(inputs)\n",
    "        ce_loss = F.binary_cross_entropy(probs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)  # pt = e^(-BCE)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        \n",
    "        return focal_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T05:50:31.097453Z",
     "iopub.status.busy": "2025-04-23T05:50:31.097061Z",
     "iopub.status.idle": "2025-04-23T05:50:31.191797Z",
     "shell.execute_reply": "2025-04-23T05:50:31.190887Z",
     "shell.execute_reply.started": "2025-04-23T05:50:31.097423Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "imgs, labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T05:50:34.795275Z",
     "iopub.status.busy": "2025-04-23T05:50:34.794948Z",
     "iopub.status.idle": "2025-04-23T05:50:36.463822Z",
     "shell.execute_reply": "2025-04-23T05:50:36.463020Z",
     "shell.execute_reply.started": "2025-04-23T05:50:34.795252Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b7_lukemelas-c5b4e57e.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b7_lukemelas-c5b4e57e.pth\n",
      "100%|██████████| 255M/255M [00:03<00:00, 69.1MB/s] \n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "config = {\n",
    "    \"lr\": 1e-4,\n",
    "    \"weight_decay\": 1e-4\n",
    "}\n",
    "\n",
    "effnet_model = EffNetB7Base(1).to(device)\n",
    "class_weights = torch.tensor([0.67, 0.33]).to(device)\n",
    "\n",
    "focal_loss = FocalLoss(alpha=0.75)\n",
    "bce_loss = nn.BCEWithLogitsLoss(pos_weight=class_weights)\n",
    "\n",
    "optimizer = torch.optim.AdamW(effnet_model.parameters(), \n",
    "                              lr=config['lr'],\n",
    "                              weight_decay=config['weight_decay'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", patience=2) # So LR doesn't plateau smh\n",
    "metric_fn = torchmetrics.F1Score(task='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# For Reference: a CrossValidator class I created back then\n",
    "\n",
    "class CrossValidator:\n",
    "    def __init__(self, \n",
    "                 models, \n",
    "                 metric_fns, \n",
    "                 cv_method, \n",
    "                 scaler = None, \n",
    "                 name = None, \n",
    "                 pi_kwargs = None, \n",
    "                 pred_probs = False, \n",
    "                 verbose = True):\n",
    "        \"\"\"\n",
    "           A class for performing cross-validation on a set of models with various metric functions.\n",
    "\n",
    "           Attributes:\n",
    "               models (list): A list of tuples containing the model name and the model object.\n",
    "               metric_fns (list): A list of tuples containing the metric name and the metric function.\n",
    "               cv_method (object): A cross-validation method object from scikit-learn.\n",
    "               scaler (object, optional): A scaler object from scikit-learn to scale the data.\n",
    "               name (str, optional): A name for the cross-validator.\n",
    "               pi_kwargs (dict, optional): A dictionary of keyword arguments for permutation importance calculation.\n",
    "               pred_probs (bool, optional): Whether to predict probabilities or class labels.\n",
    "               perm_imp (dict, optional): A dictionary containing permutation importances for each model.\n",
    "               oof_preds (dict, optional): A dictionary containing out-of-fold predictions for each model.\n",
    "               oof_metrics (dict, optional): A dictionary containing out-of-fold metric scores for each model.\n",
    "               data (tuple, optional): A tuple containing the test features and labels used in each fold.\n",
    "               oof_metrics_df (pd.DataFrame, optional): A pandas DataFrame containing the mean out-of-fold metric scores for each model.\n",
    "\n",
    "           Methods:\n",
    "               _calculate_metrics(y_test, y_pred): Calculates and prints the metric scores for a given set of true labels and predicted labels.\n",
    "               _cross_validate(X, y): Performs cross-validation on the given data and models, and stores the out-of-fold predictions, metric scores, and permutation importances.\n",
    "               _get_oof_metrics(metric_dict): Converts the out-of-fold metric scores dictionary to a pandas DataFrame.\n",
    "               fit(X, y): Initiates the cross-validation process and stores the results.\n",
    "       \"\"\"\n",
    "        \n",
    "        self.name = name\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.models = models\n",
    "        self.metric_fns = metric_fns\n",
    "        self.cv_method = cv_method\n",
    "        self.scaler = scaler\n",
    "        self.pi_kwargs = pi_kwargs\n",
    "        self.pred_probs = pred_probs\n",
    "        \n",
    "        self.perm_imp = None\n",
    "        self.oof_preds = None\n",
    "        self.oof_metrics = None\n",
    "        self.data = None\n",
    "        \n",
    "        self.oof_metrics_df = None\n",
    "    \n",
    "    def _calculate_metrics(self, y_test, y_pred):\n",
    "        # Dictionary to store the score for each metric\n",
    "        results = {}\n",
    "\n",
    "        # Loop through each metric\n",
    "        for metric_fn in self.metric_fns:\n",
    "            # Calculate score using metric\n",
    "            if metric_fn[0] == 'ROC AUC':\n",
    "                score = metric_fn[1](y_test, y_pred, multi_class = 'ovr')\n",
    "            else:\n",
    "                score = metric_fn[1](y_test, y_pred)\n",
    "\n",
    "            # Store score as value and metric as key\n",
    "            results[metric_fn[0]] = score\n",
    "            \n",
    "            if self.verbose:\n",
    "                # Display metric score\n",
    "                print(f'{metric_fn[0]} : {score:.5f}\\n')\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def _cross_validate(self, X, y):\n",
    "        # Dictionaries to store out-of-fold predictions and out-of-fold metric scores\n",
    "        oof_preds, oof_metrics = {}, {}\n",
    "        \n",
    "        # Lists to aggregate test features and labels used in each fold\n",
    "        x_data, y_data = [], []\n",
    "        \n",
    "        # Dictionary to store permutation feature importance for each fold\n",
    "        perm_imp = {}\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f'Name: {self.name} | {self.cv_method.n_splits}-Fold\\n')\n",
    "        \n",
    "        for idx, (train_idx, test_idx) in enumerate(self.cv_method.split(X, y)):\n",
    "            if self.verbose:\n",
    "                print(f'Fold {idx}:')\n",
    "                print('-'*40+'\\n')\n",
    "            \n",
    "            x_train, x_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            \n",
    "            x_data.extend(x_test)\n",
    "            y_data.extend(y_test)\n",
    "            \n",
    "            if self.scaler is not None:\n",
    "                x_train = self.scaler.fit_transform(x_train)\n",
    "                x_test = self.scaler.transform(x_test)\n",
    "            \n",
    "            for model in self.models:\n",
    "                if self.verbose:\n",
    "                    print(f'Cross-validating: [{model[0]}]\\n')\n",
    "                \n",
    "                model[1].fit(x_train, y_train)\n",
    "                \n",
    "                if model[0] not in oof_preds:\n",
    "                    oof_preds[model[0]] = []\n",
    "                    oof_metrics[model[0]] = {}                    \n",
    "                    perm_imp[model[0]] = []\n",
    "                \n",
    "                y_pred = model[1].predict_proba(x_test) if self.pred_probs else model[1].predict(x_test)\n",
    "                \n",
    "                # Save model predictions\n",
    "                oof_preds[model[0]].append(y_pred)\n",
    "                \n",
    "                # Calculate metrics\n",
    "                for metric_name, result in self._calculate_metrics(y_test, y_pred).items():\n",
    "                    # Save metric result if not already in dictionary\n",
    "                    if metric_name not in oof_metrics[model[0]]:\n",
    "                        oof_metrics[model[0]][metric_name] = []\n",
    "                    oof_metrics[model[0]][metric_name].append(result)\n",
    "                \n",
    "                # Calculate permutation importances\n",
    "                if self.pi_kwargs is not None:\n",
    "                    if self.verbose:\n",
    "                        print(' -- Calculating Permutation Importances...\\n')\n",
    "                    perm_result = permutation_importance(model[1], x_test, y_test, **self.pi_kwargs)\n",
    "                    perm_imp[model[0]].append(perm_result.importances)\n",
    "        \n",
    "        if self.pi_kwargs is not None:\n",
    "            self.perm_imp = perm_imp\n",
    "        \n",
    "        return oof_preds, oof_metrics, (x_data, y_data)\n",
    "    \n",
    "    def _get_oof_metrics(self, metric_dict):\n",
    "        dict, df = {'models' : []}, pd.DataFrame()\n",
    "        \n",
    "        for model in list(metric_dict.keys()):\n",
    "            dict['models'].append(model)\n",
    "            for metric in list(metric_dict[model].keys()):\n",
    "                if metric not in dict:\n",
    "                    dict[metric] = []\n",
    "                dict[metric].append(np.mean(metric_dict[model][metric]))\n",
    "\n",
    "        df.index = dict['models']\n",
    "        for metric in list(dict.keys())[1:]:\n",
    "            df[metric] = dict[metric]\n",
    "\n",
    "        return df      \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.oof_preds, self.oof_metrics, self.data = self._cross_validate(X, y)\n",
    "        self.oof_metrics_df = self._get_oof_metrics(self.oof_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T05:50:40.436034Z",
     "iopub.status.busy": "2025-04-23T05:50:40.435725Z",
     "iopub.status.idle": "2025-04-23T05:50:40.444586Z",
     "shell.execute_reply": "2025-04-23T05:50:40.443529Z",
     "shell.execute_reply.started": "2025-04-23T05:50:40.436013Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    train_loader, \n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    metric_fn,\n",
    "    device,\n",
    "    scheduler=None,\n",
    "):\n",
    "    model.train()\n",
    "    running_metric = 0.0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with tqdm(train_loader, unit=\"batch\", desc=\"Training\") as progress_bar:\n",
    "        for batch, (x, y) in enumerate(progress_bar):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            yhat = model(x) # Model returns logits,\n",
    "            yhat = torch.sigmoid(yhat) # Apply sigmoid for pred probs !!! \n",
    "\n",
    "            loss = loss_fn(yhat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            metric_fn.update(yhat, y)\n",
    "            running_loss += loss.item()\n",
    "            running_metric += metric_fn.compute().item()\n",
    "\n",
    "            progress_bar.set_postfix(loss=loss.item(), \n",
    "                                     metric=running_metric / (batch + 1))\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_metric = running_metric / len(train_loader)\n",
    "\n",
    "    metric_fn.reset()\n",
    "\n",
    "    print(f\"\\nTraining Loss: {epoch_loss:.4f}, F1 Score: {epoch_metric:.4f}\")\n",
    "    return epoch_loss, epoch_metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T05:50:40.756234Z",
     "iopub.status.busy": "2025-04-23T05:50:40.755902Z",
     "iopub.status.idle": "2025-04-23T05:50:40.763685Z",
     "shell.execute_reply": "2025-04-23T05:50:40.762719Z",
     "shell.execute_reply.started": "2025-04-23T05:50:40.756211Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def validate_model(\n",
    "    model,\n",
    "    valid_loader,\n",
    "    loss_fn,\n",
    "    metric_fn,\n",
    "    device\n",
    "):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_metric = 0.0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        with tqdm(valid_loader, unit=\"batch\", desc=\"Validation\") as progress_bar:\n",
    "            for x, y in progress_bar:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "\n",
    "                yhat = model(x)\n",
    "                yhat = torch.sigmoid(yhat)\n",
    "\n",
    "                loss = loss_fn(yhat, y)\n",
    "\n",
    "                metric_fn.update(yhat, y)\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                running_metric += metric_fn.compute().item()\n",
    "\n",
    "                progress_bar.set_postfix(loss=loss.item(), \n",
    "                                         metric=running_metric / (len(progress_bar) + 1))\n",
    "\n",
    "    epoch_loss = running_loss / len(valid_loader)\n",
    "    epoch_metric = running_metric / len(valid_loader)\n",
    "\n",
    "    metric_fn.reset()\n",
    "\n",
    "    print(f\"\\nValidation Loss: {epoch_loss:.4f}, F1 Score: {epoch_metric:.4f}\")\n",
    "    return epoch_loss, epoch_metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T05:50:56.814189Z",
     "iopub.status.busy": "2025-04-23T05:50:56.813594Z",
     "iopub.status.idle": "2025-04-23T05:50:56.820536Z",
     "shell.execute_reply": "2025-04-23T05:50:56.819499Z",
     "shell.execute_reply.started": "2025-04-23T05:50:56.814162Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def training_pipeline(\n",
    "    epochs,\n",
    "    model,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    loss_fn,\n",
    "    metric_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    scheduler=None,\n",
    "):\n",
    "    train_losses, valid_losses = [], []\n",
    "    train_metrics, valid_metrics = [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "        train_loss, train_metric = train_model(\n",
    "            model, train_loader, loss_fn, optimizer, metric_fn, device, scheduler\n",
    "        )\n",
    "        valid_loss, valid_metric = validate_model(\n",
    "            model, valid_loader, loss_fn, metric_fn, device\n",
    "        )\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "        train_metrics.append(train_metric)\n",
    "        valid_metrics.append(valid_metric)\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step(valid_loss)\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Metric: {train_metric:.4f}\")\n",
    "        print(f\"Validation Loss: {valid_loss:.4f}, Validation Metric: {valid_metric:.4f}\")\n",
    "\n",
    "    return train_losses, valid_losses, train_metrics, valid_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_losses, valid_losses, train_metrics, valid_metrics = training_pipeline(\n",
    "#     10, effnet_model, train_loader, valid_loader, focal_loss, metric_fn, optimizer, device, scheduler\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T05:50:58.770383Z",
     "iopub.status.busy": "2025-04-23T05:50:58.769536Z",
     "iopub.status.idle": "2025-04-23T05:51:40.341625Z",
     "shell.execute_reply": "2025-04-23T05:51:40.340128Z",
     "shell.execute_reply.started": "2025-04-23T05:50:58.770352Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/405033 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_losses, valid_losses, train_metrics, valid_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m\t\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffnet_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfocal_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 18\u001b[0m, in \u001b[0;36mtraining_pipeline\u001b[0;34m(epochs, model, train_loader, valid_loader, loss_fn, metric_fn, optimizer, device, scheduler)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m     train_loss, train_metric \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     valid_loss, valid_metric \u001b[38;5;241m=\u001b[39m validate_model(\n\u001b[1;32m     22\u001b[0m         model, valid_loader, loss_fn, metric_fn, device\n\u001b[1;32m     23\u001b[0m     )\n\u001b[1;32m     25\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[22], line 16\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, loss_fn, optimizer, metric_fn, device, scheduler)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(train_loader, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m progress_bar:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(progress_bar):\n\u001b[0;32m---> 16\u001b[0m         x, y \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     20\u001b[0m         yhat \u001b[38;5;241m=\u001b[39m model(x) \u001b[38;5;66;03m# Model returns logits,\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# The issue with the generation likely lies in the mismatch between the expected input and output shapes or values during training. Specifically:\n",
    "\n",
    "# 1. **Label Shape Mismatch**: The `labels` tensor has a value of `tensor([[60184.]])`, which is a very large value and not in the expected range for binary classification (e.g., 0 or 1). This could cause issues when computing the loss, as the model expects binary labels.\n",
    "\n",
    "# 2. **Loss Function Expectation**: The `FocalLoss` and `BCEWithLogitsLoss` expect the `targets` (labels) to be in the range `[0, 1]` for binary classification. If the labels are not normalized or are incorrect, this will lead to errors or unexpected behavior.\n",
    "\n",
    "# 3. **CUDA Error**: The error `RuntimeError: CUDA error: device-side assert triggered` often occurs when there is a mismatch in tensor shapes or invalid values (e.g., labels out of range). This could be due to the large label values or incorrect tensor dimensions.\n",
    "\n",
    "# ### Suggested Fixes:\n",
    "# - **Normalize Labels**: Ensure that the `label` column in `train_df` and `valid_df` contains binary values (0 or 1) for binary classification. If the labels are not binary, preprocess them accordingly.\n",
    "  \n",
    "#   Example:\n",
    "  ```python\n",
    "  train_df['label'] = (train_df['label'] > 0).astype(float)  # Convert to binary labels\n",
    "  valid_df['label'] = (valid_df['label'] > 0).astype(float)\n",
    "  ```\n",
    "\n",
    "# - **Check Tensor Shapes**: Verify that the shapes of `yhat` (model output) and `y` (labels) match during training. Both should have the same shape, e.g., `[batch_size, 1]`.\n",
    "\n",
    "# - **Debugging with CPU**: Set `CUDA_LAUNCH_BLOCKING=1` to get a more accurate stack trace for debugging. Alternatively, run the code on the CPU to identify the exact issue.\n",
    "\n",
    "# - **Inspect Dataset**: Check the `ICAODataset` class to ensure that the `label` tensor is being correctly created and matches the expected format.\n",
    "\n",
    "# By addressing these issues, the training pipeline should work as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, valid_losses, train_metrics, valid_metrics = training_pipeline(\n",
    "    10, effnet_model, train_loader, valid_loader, focal_loss, metric_fn, optimizer, device, scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    \"epoch\": list(range(1, len(train_losses) + 1)),\n",
    "    \"train_loss\": train_losses,\n",
    "    \"valid_loss\": valid_losses,\n",
    "    \"train_f1\": train_metrics,\n",
    "    \"valid_f1\": valid_metrics\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"training_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11965955,
     "sourceId": 97741,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
