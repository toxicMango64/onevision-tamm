# Tammathon 2025

## Our solution model to all the tasks for the Taamathon 2025

This text outlines an AI challenge focused on **developing a cat facial recognition model** to help reunite lost pets with their owners in the UAE, where many go missing annually despite existing identification methods. Participants are tasked with **training a machine learning model** using provided datasets of cat images to accurately identify individual cats based on their unique facial features. Submissions will be evaluated using **Top-3 Accuracy**, requiring participants to submit the top three predicted identities for each test image in a specific CSV format. The competition includes **public and private leaderboards**, submission limits, and a requirement for code sharing and reproducibility, emphasizing original work in leveraging AI for pet identification.


## Overview

This project implements an image similarity model using a modified ResNet50 architecture. The model extracts embeddings from images in the training dataset, which are then used to evaluate similarity and accuracy through a validation set. The embeddings are generated by removing the last layer of the ResNet50 model, allowing us to focus on the feature representations of the images.
The backbone of the model is ResNet50, which is utilized to extract image embeddings. The last layer is removed to obtain the feature embeddings of the images instead of class predictions. The dataset is managed through a custom `CatDataset` class, which loads images and their corresponding labels.
The model applies various data augmentations during training, including random cropping, flipping, color jittering, and normalization, to increase the diversity of the training dataset, improve the model's robustness, and reduce overfitting.
We experimented with different loss functions, including:
- **ArcMargin Product Loss**: Enhances the discriminative power of the embeddings.
- **Contrastive Loss**: Operates on pairs of samples, minimizing the distance for positive pairs and maximizing it for negative pairs, often with a defined margin.
- **Triplet Margin Loss**: Focuses on the relative distances between anchor, positive, and negative samples.

### Retrieval Metrics
The model calculates the top 3 accuracy using a custom metric class `RetrievalAtK`, which evaluates how well the model retrieves the closest labels based on the embeddings.
### Memory Optimization
The training loop employs Automatic Mixed Precision (AMP) and gradient scaling to improve memory efficiency and performance, addressing common issues such as vanishing gradients.
## Training Process
The training process involves the following steps:
1. **Data Preparation**: Load and preprocess the dataset, applying transformations and creating data loaders for training and validation.
2. **Model Initialization**: Instantiate the ResNet50 model and configure it for training, including setting up the optimizer and learning rate scheduler.
3. **Training Loop**: The model is trained over a specified number of epochs, with periodic validation to monitor performance. The training loop includes:
   - Forward pass through the model
   - Loss computation using the selected loss function
   - Backward pass and optimization step
   - Validation to compute retrieval metrics
4. **Saving Results**: After training, the model's state, embeddings, and training history are saved for future evaluation and analysis.

## Conclusion
This implementation provides a robust framework for image similarity tasks using deep learning. The adjustments made to the training pipeline have improved memory efficiency and tracking of training metrics, allowing for a more effective evaluation of model performance.
